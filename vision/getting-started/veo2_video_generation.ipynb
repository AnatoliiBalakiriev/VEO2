{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnatoliiBalakiriev/VEO2/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KjTHAV8FgEza"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Veo 2 Video Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fveo2_video_generation.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUCUMoTmN_lJ"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Katie Nguyen](https://github.com/katiemn) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Veo 2 on Vertex AI brings Google's state of the art video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
        "\n",
        "In this tutorial, you will learn how to use the Google Gen AI SDK for Python to interact with Veo 2 and generate new videos from text prompts and input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uerc9Xhf1f"
      },
      "source": [
        "### Install Google Gen AI SDK for Python and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rJyFNKoQhiwF",
        "outputId": "65cf75d4-d73a-4920-aeb1-87954677fb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai\n",
        "%pip install -q mediapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrasKoriKZn"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import urllib\n",
        "\n",
        "from PIL import Image as PIL_Image\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GtjPBmYHiEfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f1a560-cf1b-4e27-aa1a-3e9ed6eb7aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Project ID from Colab form/config: gen-lang-client-0279389978\n",
            "Using Location: us-central1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "CONFIG_PROJECT_ID = \"gen-lang-client-0279389978\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "# Optionally, allow override from GOOGLE_CLOUD_PROJECT environment variable if it's set.\n",
        "ENV_PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "\n",
        "if ENV_PROJECT_ID:\n",
        "    PROJECT_ID = ENV_PROJECT_ID\n",
        "    print(f\"Using Project ID from environment variable: {PROJECT_ID}\")\n",
        "else:\n",
        "    PROJECT_ID = CONFIG_PROJECT_ID\n",
        "    print(f\"Using Project ID from Colab form/config: {PROJECT_ID}\")\n",
        "\n",
        "# Final sanity check to prevent using \"None\" or an empty string\n",
        "if not PROJECT_ID or PROJECT_ID.lower() == \"none\" or PROJECT_ID.strip() == \"\":\n",
        "    raise ValueError(\n",
        "        f\"Project ID is invalid ('{PROJECT_ID}'). \"\n",
        "        \"Please ensure the Colab form has your correct project ID, or that \"\n",
        "        \"the GOOGLE_CLOUD_PROJECT environment variable is set correctly if you intend to use it.\"\n",
        "    )\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "print(f\"Using Location: {LOCATION}\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "### Define helper functions to display media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GUrEwbvFiPhJ"
      },
      "outputs": [],
      "source": [
        "def show_video(gcs_uri):\n",
        "    file_name = gcs_uri.split(\"/\")[-1]\n",
        "    # Ensure gsutil is available and user is authenticated for it in Colab\n",
        "    get_ipython().system(f\"gsutil cp {gcs_uri} {file_name}\")\n",
        "    media.show_video(media.read_video(file_name), height=500)\n",
        "\n",
        "\n",
        "def display_images(image) -> None:\n",
        "    fig, axis = plt.subplots(1, 1, figsize=(12, 6))\n",
        "    axis.imshow(image)\n",
        "    axis.set_title(\"Starting Image\")\n",
        "    axis.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jaSOOadiUj6"
      },
      "source": [
        "### Load the video generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "APRfTklCiYR2"
      },
      "outputs": [],
      "source": [
        "video_model = \"veo-2.0-generate-001\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDaTx8WCidRG"
      },
      "source": [
        "### Generate videos from a text prompt\n",
        "\n",
        "With Veo 2, you have the option to generate 8 second videos from a text prompt. In order to generate a video in the following sample, specify the following info:\n",
        "- **Prompt:** A detailed description of the video you would like to see.\n",
        "- **Aspect ratio:** Select either 16:9 or 9:16.\n",
        "- **File location:** The generated video will be shown below with support from a previously defined helper function. The video will also be stored in Cloud Storage once video generation is complete. Specify the file path where you would like this video to be stored in the output_gcs field.\n",
        "- **Number of videos:** Set this value to 1 or 2.\n",
        "- **Video duration:** Can 5, 6, 7, or 8 seconds.\n",
        "- **Prompt enhancement:** The `veo-2.0-generate-001` model offers the option to enhance your provided prompt. To utilize this feature, set `enhance_prompt` to True. A new, detailed prompt will be created from your original one to help generate higher quality videos that better adhere to your prompt's intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tygfLLlWyTo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff5804c-f54a-4e47-ce5a-27f473e3bc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting video generation with model: veo-2.0-generate-001 in project: gen-lang-client-0279389978\n"
          ]
        }
      ],
      "source": [
        "prompt = \"A heartwarming birthday scene in a cozy vintage-style apartment. A woman with long dark hair, wearing a bright red dress, stands smiling with joy, holding a large vibrant bouquet of orange and yellow roses wrapped in green paper with a yellow ribbon. She gently adjusts the bouquet and looks around happily. The room is decorated with classic golden-patterned wallpaper and colorful paintings on the walls. Add subtle birthday decorations: balloons in warm tones, softly floating confetti, and glowing fairy lights in the background. The camera slowly zooms in as soft sunlight shines through a window, casting a golden glow on her face and flowers. Add a glowing birthday message in Ukrainian: “Щасливого Дня Народження!” appearing briefly on screen. The atmosphere is filled with warmth, joy, and celebration. Style: Realistic with cinematic lighting, 4K detail, soft depth of field. Gently moving elements: hair, flowers, confetti. Emotion: tender, festive, sincere.\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://dream-videos-bucket\"  # @param {type: 'string'}\n",
        "print(f\"Attempting video generation with model: {video_model} in project: {PROJECT_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "BQztRCnBQFWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# while not operation.done:\n",
        "#     time.sleep(15)\n",
        "#     operation = client.operations.get(operation)\n",
        "#     print(operation)\n",
        "\n",
        "# if operation.response:\n",
        "#     show_video(operation.result.generated_videos[0].video.uri)"
      ],
      "metadata": {
        "id": "x5_kfhGJQIQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil iam ch user:cloud-lvm-video-server@prod.google.com:objectCreator gs://dream-videos-bucket"
      ],
      "metadata": {
        "id": "8bM2DCPtQX29"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Video generation operation started...\")\n",
        "while not operation.done: # operation.done might be a property or a method operation.done()\n",
        "    print(\"Waiting for operation to complete...\")\n",
        "    time.sleep(15)\n",
        "    # The way to refresh/get operation status might differ.\n",
        "    # If 'operation' is a google.api_core.operation.Operation, then .done is a property.\n",
        "    # The original code client.operations.get(operation) implies 'operation' itself is not the LRO object\n",
        "    # but perhaps a reference or name. This depends heavily on what client.models.generate_videos returns.\n",
        "    # Let's assume the initial 'operation' object has a 'name' or similar attribute for polling.\n",
        "    # And that client.operations.get() is the correct way to poll.\n",
        "    # If 'operation' is already the LRO object, you might just check 'operation.done'.\n",
        "    # The original code was: operation = client.operations.get(operation)\n",
        "    # This suggests 'operation' might need to be an operation name.\n",
        "    # If client.models.generate_videos returns an LRO object directly:\n",
        "    # if hasattr(operation, 'operation') and hasattr(operation.operation, 'name'):\n",
        "    #     operation_name = operation.operation.name\n",
        "    # else if hasattr(operation, 'name'):\n",
        "    #     operation_name = operation.name\n",
        "    # else:\n",
        "    #     print(\"Cannot determine operation name for polling. Assuming 'operation' object updates itself.\")\n",
        "    #     # If 'operation' updates itself, the loop is fine. Otherwise, polling needs an ID.\n",
        "    #     # For now, sticking to your original polling logic, assuming 'operation' can be passed to get()\n",
        "\n",
        "    # The error indicates the initial call fails, so polling logic is secondary for now.\n",
        "    # However, if client.models.generate_videos returns an object that has a 'name' attribute for the LRO:\n",
        "    try:\n",
        "        operation_name = operation.name # Common for LROs from google-cloud libraries\n",
        "                                        # Or operation.operation.name if it's nested\n",
        "        operation = client.operations.get(operation) # Pass as named argument 'name'\n",
        "    except AttributeError:\n",
        "        print(\"Warning: Could not get operation name for polling. The 'operation' object might update in place or polling might fail.\")\n",
        "        # If the operation object updates itself, this is fine.\n",
        "        # If client.operations.get() expects the raw operation object itself, your original code was fine for that part.\n",
        "\n",
        "    print(f\"Operation status: {operation.metadata if hasattr(operation, 'metadata') else 'N/A'}\")\n",
        "\n",
        "\n",
        "if operation.response:\n",
        "    print(\"Operation successful!\")\n",
        "    # Accessing result might be operation.result() if it's a future-like object\n",
        "    video_uri = operation.result().generated_videos[0].video.uri if callable(operation.result) else operation.response.generated_videos[0].video.uri\n",
        "    show_video(video_uri)\n",
        "else:\n",
        "    print(\"Operation may have failed or did not produce a response in the expected way.\")\n",
        "    if operation.error:\n",
        "        print(f\"Error: {operation.error}\")"
      ],
      "metadata": {
        "id": "Q5HiGyqbQPV-",
        "outputId": "aa2633f4-b125-46ed-8e95-1ffa0e1c9222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video generation operation started...\n",
            "Operation may have failed or did not produce a response in the expected way.\n",
            "Error: {'code': 7, 'message': \"cloud-lvm-video-server@prod.google.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist). cloud-lvm-video-server@prod.google.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688nb6GEwqR4"
      },
      "source": [
        "When generating videos of people you can also set the `person_generation` parameter accordingly:\n",
        "* `person_generation`: allow_adult, dont_allow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp0K0WYUwxLJ"
      },
      "outputs": [],
      "source": [
        "prompt = \"sculpting a bowl on a pottery wheel\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"9:16\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=7,\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YysYLyiVj8Zd"
      },
      "source": [
        "### Generate videos from an image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NdoBONKpJD"
      },
      "source": [
        "#### Load the starting image\n",
        "\n",
        "You can also generate a video by starting with an input image. Add the Cloud Storage file location of the image you'd like to use to display it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl_lTdvEIt8k"
      },
      "outputs": [],
      "source": [
        "image_show = PIL_Image.open(\n",
        "    urllib.request.urlopen(\n",
        "        \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/flowers.png\"\n",
        "    )\n",
        ")\n",
        "display_images(image_show)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCc77j59KjGN"
      },
      "source": [
        "#### Send the video request\n",
        "\n",
        "If you're generating a video from an image you don't need to provide a prompt. The model will simply add motion to your image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFgQYeXHnidx"
      },
      "outputs": [],
      "source": [
        "image_gcs = (\n",
        "    \"gs://cloud-samples-data/generative-ai/image/flowers.png\"  # @param {type: 'string'}\n",
        ")\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    image=types.Image(\n",
        "        gcs_uri=image_gcs,\n",
        "        mime_type=\"image/png\",\n",
        "    ),\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        person_generation=\"allow_adult\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "veo2_video_generation.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}